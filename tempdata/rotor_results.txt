Loading gpt2...
Loaded pretrained model gpt2 into HookedTransformer

--- Testing Geometric Algebra Rotor Hypothesis (Layer 6) ---
Extracting training vectors...
Optimal Rotation Found. Scale (singular values sum): 123893.6797

Evaluating on Test Set...
Vector Translation - MSE: 55.4843, CosSim: 0.8361
Rotor (Rotation)   - MSE: 67.9414, CosSim: 0.7796
Improvement in MSE: -22.45%

Norm Analysis (Output/Input Ratio):
True Relation Ratio: 0.9502
Vector Pred Ratio  : 0.9136
Rotor Pred Ratio   : 1.0000 (Should be 1.0 for orthogonal matrix)
Conclusion: Rotor hypothesis does NOT improve over Vector hypothesis.
